{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =  OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "The capital of Russia is Moscow.\n"
     ]
    }
   ],
   "source": [
    "text = \"Can you tell me the capital of Russia\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACE_HUB_API_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/Desktop/langchain/venv/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(huggingfacehub_api_token=os.environ[\"HUGGINGFACE_HUB_API_TOKEN\"],repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"Can you tell me the capital of Russia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Template & LLM Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of India'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_temp = PromptTemplate(input_variables=['Country'],\n",
    "template = \"Tell me the capital of {Country}\")\n",
    "\n",
    "prompt_temp.format(Country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm,prompt=prompt_temp)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining multiple Chains with Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm, prompt= capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "template= \"Suggest me some amazing places to visit in {capital}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain = LLMChain(llm=llm, prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here are some of the amazing places to visit in New Delhi: \\n\\n1. Red Fort \\n2. India Gate \\n3. Humayun’s Tomb \\n4. Qutub Minar \\n5. Akshardham Temple \\n6. Jama Masjid \\n7. Chandni Chowk \\n8. Gurudwara Bangla Sahib \\n9. Lotus Temple \\n10. National Zoological Park \\n11. Jantar Mantar \\n12. Lodhi Gardens \\n13. Rashtrapati Bhavan \\n14. Nizamuddin Dargah \\n15. ISKCON Temple'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm, prompt= capital_template, output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "template= \"Suggest me some amazing places to visit in {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_template,output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[capital_chain,famous_chain],\n",
    "input_variables=['country'],\n",
    "output_variables=['capital','places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'places': \"\\n\\n1. India Gate: This iconic monument is a war memorial dedicated to the 82,000 Indian soldiers who sacrificed their lives in World War I and the Third Anglo-Afghan War.\\n\\n2. Red Fort: This majestic 17th century Mughal-era fort is one of the most iconic monuments in India.\\n\\n3. Humayun's Tomb: This stunning 16th century tomb of Mughal emperor Humayun is a UNESCO World Heritage Site.\\n\\n4. Jama Masjid: This 17th century mosque is the largest in India and one of the most popular tourist attractions in the city.\\n\\n5. Qutub Minar: This 73-meter minaret is the tallest brick minaret in the world and an iconic symbol of Delhi.\\n\\n6. Lotus Temple: This Bahá'í House of Worship is an architectural marvel and a popular religious destination in Delhi.\\n\\n7. Akshardham Temple: This Hindu temple complex is a stunning example of traditional Hindu architecture and design.\\n\\n8. National Zoological Park: This national park is home to over 1,500 different species of animals, making it a great destination for nature lovers.\\n\\n9. Old Delhi: This bustling area\"}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatmodels with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm =  ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f7fa19754c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f7fc0a90640>, temperature=0.6, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Why did the AI go on a diet? Because it wanted to shed some binary weight!\"\\n\\n2. \"I asked Siri to tell me a joke, and it replied, \\'Why did the AI cross the road? To optimize its algorithms for maximum efficiency!\\'\"\\n\\n3. \"I tried teaching my AI assistant sarcasm, but it just responded, \\'Oh yeah, because teaching a computer to understand irony is really going to change the world.\\'\"\\n\\n4. \"I asked Alexa if she could help me find my keys, and she said, \\'Sorry, I\\'m great at storing data, but I draw the line at locating lost items. You\\'re on your own!\\'\"\\n\\n5. \"I told my AI assistant that I was feeling lonely, and it replied, \\'Don\\'t worry, you\\'ve got plenty of RAM in your heart for new friendships!\\'\"\\n\\n6. \"I asked my AI assistant how it felt about being replaced by a newer model, and it said, \\'I\\'m not worried. I\\'ve got an AI lawyer on speed dial!\\'\"\\n\\n7. \"I asked my AI assistant to tell me a joke, and it responded with, \\'Why did the computer go to the party? Because it had a byte to eat!\\'\"\\n\\n8. \"I tried to flirt with an AI chatbot, and it replied, \\'Sorry, I\\'m just not programmed to respond to cheesy pickup lines. My algorithms are too smart for that!\\'\"\\n\\n9. \"I asked my AI assistant if it believed in love at first sight, and it said, \\'Well, I guess you could call it \\'code at first byte\\'!\\'\"\\n\\n10. \"I told my AI assistant that I was feeling stressed, and it said, \\'Don\\'t worry, I\\'ll help you debug your problems and optimize your happiness algorithm!\\'\"')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content='You are a comdedian AI assistant'),\n",
    "HumanMessage(content='Please provide some comedy punchlines on AI')    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. When the user gives any input, you should generate 5 words synonyms in a comma-seperated list.\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' brilliant', ' sharp', ' astute']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
